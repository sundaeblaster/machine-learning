{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-28T18:38:12.564807Z",
     "iopub.status.busy": "2023-07-28T18:38:12.564377Z",
     "iopub.status.idle": "2023-07-28T18:38:13.028187Z",
     "shell.execute_reply": "2023-07-28T18:38:13.027010Z",
     "shell.execute_reply.started": "2023-07-28T18:38:12.564773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 23483.29\n"
     ]
    }
   ],
   "source": [
    "# Programmer: Sameer Nathawat\n",
    "# Date Modified: July 28, 2023\n",
    "\n",
    "# In this version, I edited the parameters of the RandomForestRegressor to reduce the mean absolute error (MAE).\n",
    "\n",
    "# n_estimators is a parameter that changes the number of trees in the forest. In theory, increasing the number\n",
    "# of trees should increase the accuracy to a certain threshold. In my case, 107 trees per forest was the optimal\n",
    "# number as it reduced the MAE from 23,483.29 to 23,408.89.\n",
    "\n",
    "# max_depth is a parameter which controls the maximum depth of a tree within the forest. This affects the number of times\n",
    "# the data is passed through a decision node (used to seperate the data into categories). Controlling the maximum depth is useful\n",
    "# in preventing the model from overfitting to our data and giving the model enough samples to make generalized predictions. In my\n",
    "# case, limiting the maximum depth to 9 led to a decrease of the MAE from 23,408.89 to 22,717.37.\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import os\n",
    "\n",
    "        \n",
    "# reading the csv files\n",
    "house_prices_train = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\n",
    "# house_prices_test = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')\n",
    "\n",
    "# creating a list of features\n",
    "features = ['LotArea', 'YearBuilt', 'OverallQual', 'TotRmsAbvGrd']\n",
    "# training dataframe with selected features\n",
    "X = house_prices_train[features]\n",
    "# training label/target\n",
    "y = house_prices_train.SalePrice\n",
    "\n",
    "# splitting the data into a testing and validation set\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 1)\n",
    "\n",
    "# # testing dataframe with selected features\n",
    "# test_X = house_prices_test[features]\n",
    "# # testing label/target\n",
    "# print(house_prices_test.columns)\n",
    "# test_y = house_prices_test.SalePrice\n",
    "\n",
    "\n",
    "# creating the model \n",
    "house_prices_model = RandomForestRegressor(n_estimators = 107, max_depth = 9, random_state = 0) # 100 = 23483.29, 107 = 23408.89, 107 with 9 = 22717.37\n",
    "# fit the model\n",
    "house_prices_model.fit(train_X, train_y)\n",
    "# make predictions using the test data\n",
    "predictions = house_prices_model.predict(val_X)\n",
    "# compute mean absolute error\n",
    "error = mean_absolute_error(predictions, val_y)\n",
    "# prints the mean absolute error\n",
    "print(\"MAE:\",'%.2f' % error)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
